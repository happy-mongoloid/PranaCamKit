// swift-interface-format-version: 1.0
// swift-compiler-version: Apple Swift version 5.9 (swiftlang-5.9.0.128.108 clang-1500.0.40.1)
// swift-module-flags: -target arm64-apple-ios17.0 -enable-objc-interop -enable-library-evolution -swift-version 5 -enforce-exclusivity=checked -O -module-name PranaCamKit
// swift-module-flags-ignorable: -enable-bare-slash-regex
import AVFoundation
import MetalKit
import Photos
import PhotosUI
@_exported import PranaCamKit
import SceneKit
import Swift
import _Concurrency
import _StringProcessing
import _SwiftConcurrencyShims
public class ViTRecorder {
  public var mtlRecorder: PranaCamKit.MetalVideoRecorder!
  public var audioRecorder: PranaCamKit.AudioWriter!
  public var url: Foundation.URL
  public var recording: Swift.Bool {
    get
  }
  public init(drawableSize: CoreFoundation.CGSize)
  public func reset()
  public func flush(mtlTexture: any Metal.MTLTexture, recTime: CoreMedia.CMTime)
  public func startRec()
  public func finishRec() -> Swift.Bool
  public enum PhStatus {
    case accessed, denied
    public static func == (a: PranaCamKit.ViTRecorder.PhStatus, b: PranaCamKit.ViTRecorder.PhStatus) -> Swift.Bool
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
  }
  public func saveVideoToCameraRoll(_ comp: @escaping () -> ())
  @objc deinit
}
extension Foundation.URL {
  public func removeIfExist()
}
public class MetalVideoRecorder {
  public var writerer: AVFoundation.AVAssetWriter!
  public var isWriting: Swift.Bool
  public var started: Swift.Bool
  public init(size: CoreFoundation.CGSize, url: Foundation.URL)
  @objc deinit
  public func setupVideoWriter()
  public func start(_ time: CoreMedia.CMTime)
  public func end(_ time: CoreMedia.CMTime)
  public func flushTexture(mtlTexture: (any Metal.MTLTexture)?, recTime: CoreMedia.CMTime, failureComp: @escaping () -> ())
  public func finishRec(comp: @escaping () -> ())
}
@objc @_inheritsConvenienceInitializers public class AudioWriter : ObjectiveC.NSObject, AVFAudio.AVAudioRecorderDelegate {
  public func setup_recorder()
  public func startRec()
  public func pause()
  public func resume()
  public func stopRec()
  @objc override dynamic public init()
  @objc deinit
}
public enum CMPreset {
  case vga, hd, square
  public static func == (a: PranaCamKit.CMPreset, b: PranaCamKit.CMPreset) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
}
public protocol PCameraDelegate : AnyObject {
  func updatePixelBuffer(camera: CoreVideo.CVPixelBuffer, timestamp: CoreMedia.CMTime, recordedTime: CoreMedia.CMTime, frontCamera: Swift.Bool)
  func capturePhoto(photo: CoreVideo.CVPixelBuffer, metadata: CoreFoundation.CFDictionary)
  func exportVideo(path: Swift.String)
}
@objc final public class PVCaptureManager : ObjectiveC.NSObject, AVFoundation.AVCaptureVideoDataOutputSampleBufferDelegate, AVFoundation.AVCapturePhotoCaptureDelegate {
  weak final public var delegate: (any PranaCamKit.PCameraDelegate)?
  final public var formatDescription: CoreMedia.CMFormatDescription?
  final public var captureSession: AVFoundation.AVCaptureSession?
  final public var previewLayer: AVFoundation.AVCaptureVideoPreviewLayer?
  final public var ultraWideCamIsAvailable: Swift.Bool
  final public var ultraWideCamEnebled: Swift.Bool
  final public var bufferSize: CoreFoundation.CGSize!
  final public var recordedDuration: CoreMedia.CMTime
  final public var pixelBufferEnebled: Swift.Bool
  final public var orientation: UIKit.UIDeviceOrientation
  final public var light: Swift.Bool
  final public var usingFrontCamera: Swift.Bool
  public init(_ avPreset: AVFoundation.AVCaptureSession.Preset)
  final public func startCamera(_ comp: @escaping (Swift.Bool) -> Swift.Void)
  final public func setupMovieOutput()
  final public func addAudioInput()
  final public func startRecording()
  final public func stopRecording()
  final public func startSession()
  final public func rotateCam()
  final public func switchLight()
  final public func stopCaptureSession()
  final public func getFrontCamera() -> AVFoundation.AVCaptureDevice?
  final public func getBackCamera() -> AVFoundation.AVCaptureDevice?
  final public func changeCamera()
  final public func setVideoZoomFactor(zoomFactor: CoreFoundation.CGFloat)
  final public func setPreset(cmPreset: AVFoundation.AVCaptureSession.Preset)
  final public func toggleTorch(on: Swift.Bool)
  final public func capturePhoto(photoSettings: AVFoundation.AVCapturePhotoSettings = AVCapturePhotoSettings())
  @objc final public func photoOutput(_ output: AVFoundation.AVCapturePhotoOutput, didFinishProcessingPhoto photo: AVFoundation.AVCapturePhoto, error: (any Swift.Error)?)
  @objc final public func captureOutput(_ output: AVFoundation.AVCaptureOutput, didOutput sampleBuffer: CoreMedia.CMSampleBuffer, from connection: AVFoundation.AVCaptureConnection)
  @objc deinit
}
extension PranaCamKit.PVCaptureManager : AVFoundation.AVCaptureFileOutputRecordingDelegate {
  @objc final public func fileOutput(_ output: AVFoundation.AVCaptureFileOutput, didStartRecordingTo fileURL: Foundation.URL, from connections: [AVFoundation.AVCaptureConnection])
  @objc final public func fileOutput(_ output: AVFoundation.AVCaptureFileOutput, didFinishRecordingTo outputFileURL: Foundation.URL, from connections: [AVFoundation.AVCaptureConnection], error: (any Swift.Error)?)
}
extension PranaCamKit.ViTRecorder.PhStatus : Swift.Equatable {}
extension PranaCamKit.ViTRecorder.PhStatus : Swift.Hashable {}
extension PranaCamKit.CMPreset : Swift.Equatable {}
extension PranaCamKit.CMPreset : Swift.Hashable {}
